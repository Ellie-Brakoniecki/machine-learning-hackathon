{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", font=\"Arial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_data = pd.read_csv(\"ames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cols with more than 50% missing data and impute missing values for other cols\n",
    "threshold = len(ames_data) * 0.5\n",
    "ames_data = ames_data.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "for col in ames_data.select_dtypes(include=['float', 'int']):  #numerical cols\n",
    "    ames_data[col] = ames_data[col].fillna(ames_data[col].median())\n",
    "\n",
    "for col in ames_data.select_dtypes(include=['object']): #categorical cols\n",
    "    ames_data[col] = ames_data[col].fillna(ames_data[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ames_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(ames_data, x = 'Year Built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_top_correlations(data, target_variable, top_n=10):\n",
    "    \"\"\"\n",
    "    Plot scatter plots for the top N features most correlated with the target variable.\n",
    "    \"\"\"\n",
    "    numeric_data = data.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "    corr_matrix = numeric_data.corr()\n",
    "\n",
    "    correlations = corr_matrix[target_variable].drop(target_variable)\n",
    "    correlations = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "    top_variables = correlations.head(top_n).index\n",
    "\n",
    "    num_rows = (top_n + 1) // 2  \n",
    "    plt.figure(figsize=(15, num_rows * 5))\n",
    "    for i, column in enumerate(top_variables):\n",
    "        plt.subplot(num_rows, 2, i + 1)  \n",
    "        sns.scatterplot(data=numeric_data, x=column, y=target_variable)\n",
    "        plt.title(f\"Correlation: {column} vs {target_variable}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(target_variable)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_top_correlations(ames_data, 'Year Built', 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = [\"Year Remod/Add\", \"Overall Qual\", \"SalePrice\", \"Garage Cars\", \"Full Bath\", \"Total Bsmt SF\", \"Enclosed Porch\"]\n",
    "target_variable = \"Year Built\"\n",
    "\n",
    "X = ames_data[independent_variables]\n",
    "y = ames_data[target_variable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "print(\"Linear Regression MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "print(\"Linear Regression R² Score:\", r2_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.5)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Linear Regression: Actual vs Predicted')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Linear Regression\n",
    "lr_coef = pd.DataFrame({'Feature': independent_variables, 'Coefficient': lr.coef_})\n",
    "lr_coef = lr_coef.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=lr_coef, x='Coefficient', y='Feature')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_scaled)\n",
    "print(\"Decision Tree MSE:\", mean_squared_error(y_test, y_pred_dt))\n",
    "print(\"Decision Tree R² Score:\", r2_score(y_test, y_pred_dt))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt, filled=True, feature_names=independent_variables, max_depth=3) \n",
    "plt.show()\n",
    "\n",
    "importances = dt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances (Decision Tree)\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), [independent_variables[i] for i in indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "print(\"Random Forest MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest R² Score:\", r2_score(y_test, y_pred_rf))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances (Random Forest)\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), [independent_variables[i] for i in indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test_scaled)\n",
    "print(\"Gradient Boosting MSE:\", mean_squared_error(y_test, y_pred_gb))\n",
    "print(\"Gradient Boosting R² Score:\", r2_score(y_test, y_pred_gb))\n",
    "\n",
    "importances = gb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances (Gradient Boosting)\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), [independent_variables[i] for i in indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm = SVR()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "print(\"SVM MSE:\", mean_squared_error(y_test, y_pred_svm))\n",
    "print(\"SVM R² Score:\", r2_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_scores = {}\n",
    "\n",
    "def perform_cross_validation(model, X, y, num_folds=5):\n",
    "    scores = cross_val_score(model, X, y, cv=num_folds, scoring='r2')\n",
    "    print(f\"Average R² Score ({num_folds}-Fold): {np.mean(scores)}\")\n",
    "    return scores\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "all_scores[\"Linear Regression\"] = perform_cross_validation(lr, X_train_scaled, y_train)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "all_scores[\"Decision Tree\"] = perform_cross_validation(dt, X_train_scaled, y_train)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "all_scores[\"Random Forest\"] = perform_cross_validation(rf, X_train_scaled, y_train)\n",
    "\n",
    "print(\"Gradient Boosting\")\n",
    "all_scores[\"Gradient Boosting\"] = perform_cross_validation(gb, X_train_scaled, y_train)\n",
    "\n",
    "print(\"SVM\")\n",
    "all_scores[\"Support Vector Machine\"] = perform_cross_validation(svm, X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(columns=[1,2,3,4,5])\n",
    "for x, y in all_scores.items():\n",
    "    scores_df.loc[x, [1,2,3,4,5]] = y\n",
    "scores_df[\"mean\"] = scores_df[[1,2,3,4,5]].mean(axis=1)\n",
    "scores_df[\"sd\"] = scores_df[[1,2,3,4,5]].std(axis=1)\n",
    "scores_df[\"min\"] = scores_df[[1,2,3,4,5]].min(axis=1)\n",
    "scores_df[\"max\"] = scores_df[[1,2,3,4,5]].max(axis=1)\n",
    "# scores_df[\"errorbar\"] = scores_df.apply(lambda x: tuple(x[\"min\"], x[\"max\"]))\n",
    "scores_df = scores_df.reset_index().rename({\"index\": \"Model\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(7)\n",
    "sns.barplot(data=scores_df, y=\"Model\", x=\"mean\", ax=ax)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"Mean $R^2$ Score\")\n",
    "plt.ylabel(None)\n",
    "plt.title(\"Comparison of $R^2$ scores across models\")\n",
    "\n",
    "ax.grid(True, axis=\"x\", which=\"major\")\n",
    "ax.bar_label(ax.containers[0], labels=scores_df[\"mean\"].round(3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best R² Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "sns.scatterplot(x=y_test, y=y_test-y_pred_lr, ax=ax[0])\n",
    "ax[0].axhline(y=0, color='r', linestyle='--')\n",
    "ax[0].title.set_text(\"Linear Regression\")\n",
    "\n",
    "sns.scatterplot(x=y_test, y=y_test-y_pred_rf, ax=ax[1])\n",
    "ax[1].axhline(y=0, color='r', linestyle='--')\n",
    "ax[1].title.set_text(\"Random Forest\")\n",
    "\n",
    "plt.suptitle(\"Comparison of Residuals between Models\")\n",
    "\n",
    "ax[0].grid(True, axis=\"y\")\n",
    "ax[1].grid(True, axis=\"y\")\n",
    "\n",
    "ax[0].set_ylabel(\"Residual\")\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0)\n",
    "plt.ylim(-100, 75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y_test, y_pred, model_name):\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_test, y=residuals)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'Residuals vs Actual for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "plot_residuals(y_test, y_pred_lr, 'Linear Regression')\n",
    "plot_residuals(y_test, y_pred_dt, 'Decision Tree')\n",
    "plot_residuals(y_test, y_pred_rf, 'Random Forest')\n",
    "plot_residuals(y_test, y_pred_gb, 'Gradient Boosting')\n",
    "plot_residuals(y_test, y_pred_svm, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "##### Model Performance:\n",
    "\n",
    "Random Forest and Gradient Boosting have the best performance based on R² Score and MSE.\n",
    "Linear Regression and SVM show moderate performance.\n",
    "Decision Tree has the lowest performance, which is could be due to its tendency to overfit.\n",
    "\n",
    "##### Cross-Validation Scores:\n",
    "\n",
    "The cross-validation scores are slightly lower than the test scores which is normal. This suggests our models are not overfitting significantly.\n",
    "Random Forest and Gradient Boosting consistently show strong performance, reinforcing their robustness.\n",
    "\n",
    "##### Hyperparameter Tuning:\n",
    "\n",
    "For Random Forest, the best parameters (max_depth: 20, n_estimators: 300) indicate a preference for a more complex model, which makes sense given the dataset's complexity.\n",
    "\n",
    "##### Residual Analysis \n",
    "\n",
    "Residuals do not have constant variance(not homoscedastic) for all of our models. This suggests a systematic bias in model predictions - underestimating the year built for older \n",
    "houses and overestimating it for new ones. \n",
    "\n",
    "To address this we can try: \n",
    "- Non-Linear Relationships: including polynomial terms to capture non-linear relationships\n",
    "- Feature Engineering: revisit feature selection and engineering process\n",
    "- Data quality/ removing outliers\n",
    "- Try more complex models to see if they can capture underlying patterns in the data\n",
    "- Use temporal features eg create a feature that represents the age of a house at time of sale\n",
    "- Residual analysis over time \n",
    "- Model diagnostics: check for multicollinearity, overfitting, violation of model assumptions\n",
    "\n",
    "\n",
    "TO-DO\n",
    "- evalate efficiency of each model - time taken, resource consumption?? \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "rf_poly = RandomForestRegressor(random_state=42)\n",
    "rf_poly.fit(X_train_poly_scaled, y_train_poly)\n",
    "\n",
    "y_pred_rf_poly = rf_poly.predict(X_test_poly_scaled)\n",
    "print(\"Random Forest with Polynomial Features MSE:\", mean_squared_error(y_test_poly, y_pred_rf_poly))\n",
    "print(\"Random Forest with Polynomial Features R² Score:\", r2_score(y_test_poly, y_pred_rf_poly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "residuals_poly = y_test_poly - y_pred_rf_poly\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test_poly, y=residuals_poly)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Year Built')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Year Built for Random Forest with Polynomial Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.histplot(data=ames_data, x=\"Year Built\", binwidth=1)\n",
    "plt.grid(True, axis=\"y\")\n",
    "plt.title(\"Distribution of Target Variable (Year Built)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4caf6cf0f571f7c6c6625dbdef43533d1d6b76f53b83dcc43bcb6312d031aa1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
